{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary libraries\n",
    "from ultralytics import YOLO\n",
    "import torch\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from segment_anything import SamPredictor, sam_model_registry\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "import glob\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the SAM masks for each image to determine accuracy\n",
    "\n",
    "# set the path to the folder containing the images\n",
    "folder_path = #path to folder containing images\n",
    "output_folder = #path to folder to save segmetnation masks\n",
    "\n",
    "# load the custom YOLO model\n",
    "weight = #path to custom YOLO object detection model\n",
    "model = YOLO(weight)\n",
    "\n",
    "data = []\n",
    "\n",
    "# loop over all the files in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    # check if the file is an image\n",
    "    if filename.endswith('.png') or filename.endswith('.jpg'):\n",
    "         # extract isolate, cultivar, rep, and DAI information from the filename\n",
    "        isolate, cultivar, rep, head, DAI = filename.split('_')[:5]\n",
    "        # run the model on the image\n",
    "        image_path = os.path.join(folder_path, filename)\n",
    "        results = model.predict(image_path, conf=0.5)\n",
    "\n",
    "        # extract bounding box coordinates from the detection\n",
    "        for result in results:\n",
    "            boxes = result.boxes\n",
    "            if len(boxes) > 0:\n",
    "                bbox = boxes.xyxy.tolist()[0]\n",
    "                device = \"cuda\"\n",
    "\n",
    "        # run the segmentation model on the bounding box\n",
    "        image = cv2.cvtColor(cv2.imread(image_path), cv2.COLOR_BGR2RGB)\n",
    "        sam_checkpoint = \"sam_vit_h_4b8939.pth\"\n",
    "        model_type = \"vit_h\"\n",
    "        sam = sam_model_registry[model_type](checkpoint=sam_checkpoint)\n",
    "        sam.to(device=device)\n",
    "        predictor = SamPredictor(sam)\n",
    "        predictor.set_image(image)\n",
    "        input_box = np.array(bbox)\n",
    "        masks, _, _ = predictor.predict(\n",
    "            point_coords=None,\n",
    "            point_labels=None,\n",
    "            box=input_box[None, :],\n",
    "            multimask_output=False,\n",
    "        )\n",
    "        # Save the mask to file along with the original file name and the coordinates of the bounding box\n",
    "        mask_filename = f'{filename}.png'\n",
    "        mask_path = os.path.join(output_folder, mask_filename)\n",
    "\n",
    "        # Append the image info to the data list\n",
    "        image_info = {\n",
    "            'filename': filename,\n",
    "            'x1': bbox[0],\n",
    "            'y1': bbox[1],\n",
    "            'x2': bbox[2],\n",
    "            'y2': bbox[3],\n",
    "            'mask_path': mask_path\n",
    "        }\n",
    "        data.append(image_info)\n",
    "\n",
    "        # Convert the array to a PIL image\n",
    "        mask_image = Image.fromarray((masks[0] * 255).astype(np.uint8))\n",
    "\n",
    "        # Save the mask to file\n",
    "        mask_image.save(mask_path)\n",
    "\n",
    "        # Convert the PIL image to a numpy array\n",
    "        mask = np.array(mask_image)\n",
    "\n",
    "        # Convert the image to a supported data type\n",
    "        mask = mask.astype(np.uint8)\n",
    "\n",
    "        # Save the mask to file\n",
    "        cv2.imwrite(mask_path, mask)\n",
    "\n",
    "# Create a DataFrame from the collected data\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save ground truth annotations to individual image files\n",
    "\n",
    "# Set the paths to the annotation and output mask folders\n",
    "image_folder = #path to folder containing images\n",
    "annotation_file = #path to json file containing hand annotations for the wheat heads\n",
    "output_mask_folder =  #path to folder to save binary masks\n",
    "\n",
    "# Loop through all the annotation files in the folder\n",
    "with open(annotation_file, 'r') as f:\n",
    "    annotations = json.load(f)\n",
    "\n",
    "# Loop over the images\n",
    "for image in annotations['images']:\n",
    "    # Load the image\n",
    "    image_path = os.path.join(image_folder, image['file_name'])\n",
    "    img = cv2.imread(image_path)\n",
    "\n",
    "    # Create a binary mask from the annotations\n",
    "    mask = np.zeros_like(img[:, :, 0], dtype=np.uint8)\n",
    "    for annotation in annotations['annotations']:\n",
    "        if annotation['image_id'] == image['id']:\n",
    "            vertices = np.array(annotation['segmentation'], dtype=np.int32).reshape((-1, 2))\n",
    "            cv2.fillPoly(mask, [vertices], 255)\n",
    "\n",
    "    # Overlay the mask on the image\n",
    "    overlay = cv2.addWeighted(img, 0.5, cv2.cvtColor(mask, cv2.COLOR_GRAY2BGR), 0.5, 0)\n",
    "\n",
    "    # Convert the mask to binary\n",
    "    ret, binary_mask = cv2.threshold(mask, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Save the binary mask to file\n",
    "    binary_mask_path = os.path.join(output_mask_folder, image['file_name'].replace('.jpg', '_binary_mask.png'))\n",
    "    cv2.imwrite(binary_mask_path, binary_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the paths to the ground truth and predicted mask folders\n",
    "gt_mask_folder = # path to folder containing ground truth masks\n",
    "pred_mask_folder = # path to folder containing predicted SAM masks\n",
    "\n",
    "# Get the list of image files\n",
    "gt_mask_files = os.listdir(gt_mask_folder)\n",
    "pred_mask_files = os.listdir(pred_mask_folder)\n",
    "\n",
    "# Create a table to store the IoU data\n",
    "data = []\n",
    "for i, gt_mask_file in enumerate(gt_mask_files):\n",
    "    pred_mask_file = pred_mask_files[i]\n",
    "    assert gt_mask_file == pred_mask_file, f\"Ground truth mask file {gt_mask_file} does not match predicted mask file {pred_mask_file}\"\n",
    "    image_name = os.path.splitext(gt_mask_file)[0]\n",
    "    gt_mask_path = os.path.join(gt_mask_folder, gt_mask_file)\n",
    "    pred_mask_path = os.path.join(pred_mask_folder, pred_mask_file)\n",
    "    gt_mask = cv2.imread(gt_mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "    pred_mask = cv2.imread(pred_mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "    intersection = cv2.bitwise_and(gt_mask, pred_mask)\n",
    "    union = cv2.bitwise_or(gt_mask, pred_mask)\n",
    "    iou = cv2.countNonZero(intersection) / cv2.countNonZero(union)\n",
    "    data.append({'image_name': image_name, 'iou': iou})\n",
    "\n",
    "# Calculate the overall IoU\n",
    "iou_values = [d['iou'] for d in data]\n",
    "overall_iou = sum(iou_values) / len(iou_values)\n",
    "\n",
    "# Create a DataFrame from the collected data\n",
    "df = pd.DataFrame(data)\n",
    "df\n",
    "\n",
    "# save the dataframe to a csv file\n",
    "df.to_csv(#path to save csv file)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
