{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary libraries\n",
    "from ultralytics import YOLO\n",
    "import torch\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from segment_anything import SamPredictor, sam_model_registry\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "import glob\n",
    "import supervision as sv\n",
    "from scipy.stats import gaussian_kde\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "import plotly.express as px\n",
    "import mplcursors\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, precision_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define mask and box functions\n",
    "def show_mask(mask, ax, random_color=False):\n",
    "    if random_color:\n",
    "        color = np.concatenate([np.random.random(3), np.array([0.6])], axis=0)\n",
    "    else:\n",
    "        color = np.array([30/255, 144/255, 255/255, 0.6])\n",
    "    h, w = mask.shape[-2:]\n",
    "    mask_image = mask.reshape(h, w, 1) * color.reshape(1, 1, -1)\n",
    "    ax.imshow(mask_image)\n",
    "    \n",
    "def show_points(coords, labels, ax, marker_size=375):\n",
    "    pos_points = coords[labels==1]\n",
    "    neg_points = coords[labels==0]\n",
    "    ax.scatter(pos_points[:, 0], pos_points[:, 1], color='green', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)\n",
    "    ax.scatter(neg_points[:, 0], neg_points[:, 1], color='red', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)   \n",
    "    \n",
    "def show_box(box, ax):\n",
    "    x0, y0 = box[0], box[1]\n",
    "    w, h = box[2] - box[0], box[3] - box[1]\n",
    "    ax.add_patch(plt.Rectangle((x0, y0), w, h, edgecolor='green', facecolor=(0,0,0,0), lw=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the custom YOLO model\n",
    "weight = #path to custom YOLO object detection model\n",
    "model = YOLO(weight)\n",
    "\n",
    "# run the model on a single image\n",
    "results = model.predict(#path to image, conf=0.5)\n",
    "\n",
    "# extract bounding box coordinates from the detection\n",
    "for result in results:\n",
    "    boxes = result.boxes\n",
    "bbox = boxes.xyxy.tolist()[0]\n",
    "device = \"cuda\"\n",
    "\n",
    "# run the segmentation model on the bounding box\n",
    "image = cv2.cvtColor(cv2.imread(#path to image), cv2.COLOR_BGR2RGB)\n",
    "sam_checkpoint = \"sam_vit_h_4b8939.pth\"\n",
    "model_type = \"vit_h\"\n",
    "sam = sam_model_registry[model_type](checkpoint=sam_checkpoint)\n",
    "sam.to(device=device)\n",
    "predictor = SamPredictor(sam)\n",
    "predictor.set_image(image)\n",
    "input_box = np.array(bbox)\n",
    "masks, _, _ = predictor.predict(\n",
    "    point_coords=None,\n",
    "    point_labels=None,\n",
    "    box=input_box[None, :],\n",
    "    multimask_output=False,\n",
    ")\n",
    "\n",
    "# save the output image with the segmentation mask as a variable\n",
    "output_image = image\n",
    "output_mask = masks[0]\n",
    "\n",
    "# get the segmentation mask\n",
    "segmentation_mask = masks[0]\n",
    "\n",
    "# convert the segmentation mask to a binary mask\n",
    "binary_mask = np.where(segmentation_mask > 0.5, 1, 0)\n",
    "\n",
    "# create a background with NA values\n",
    "na_background = np.full_like(image, np.nan)\n",
    "\n",
    "# apply the binary mask\n",
    "img_na = na_background * (1 - binary_mask[..., np.newaxis]) + image * binary_mask[..., np.newaxis]\n",
    "\n",
    "# set the red, green, and blue channels as variables\n",
    "s_r = img_na[:,:,0]\n",
    "s_g = img_na[:,:,1]\n",
    "s_b = img_na[:,:,2]\n",
    "\n",
    "# performing the red/green ratio calculation\n",
    "rg = s_r / (s_g + s_r)\n",
    "\n",
    "# set the pixels on rg that are not within the mask to NaN\n",
    "rg[~segmentation_mask] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# activate interactive mode\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the image segmentation mask and the rg transformation\n",
    "\n",
    "# Set the plot style to a dark theme\n",
    "plt.style.use('classic')\n",
    "\n",
    "# create a new figure and arrange the histogram and exgr image side by side with a colorbar, with the original image and the image with the segmentation mask above\n",
    "plt.figure(figsize=(15, 15))\n",
    "\n",
    "# Plot the original image on the top left\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.imshow(image)\n",
    "plt.title('Original Image')\n",
    "plt.axis('off')\n",
    "\n",
    "# Plot the image with the segmentation mask on the top right\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.imshow(image)\n",
    "plt.title('Segmentation Mask')\n",
    "show_mask(masks[0], plt.gca())\n",
    "show_box(input_box, plt.gca())\n",
    "plt.axis('off')\n",
    "\n",
    "# Plot the exgr image on the bottom left\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.imshow(rg, cmap='Spectral')\n",
    "plt.colorbar()\n",
    "plt.title('RG Transformation')\n",
    "\n",
    "# Filter out invalid values (inf and NaN) from the exgr array\n",
    "valid_rg = rg.ravel()[np.isfinite(rg.ravel())]\n",
    "\n",
    "# Plot the smoothed density histogram on the bottom right\n",
    "plt.subplot(2, 2, 4)\n",
    "\n",
    "# Compute the smoothed density histogram using the kernel density estimate (KDE)\n",
    "kde = gaussian_kde(valid_rg)\n",
    "x_vals = np.linspace(np.min(valid_rg), np.max(valid_rg), 500)  # Values for the x-axis\n",
    "\n",
    "# Obtain colors from the 'viridis' colormap for the histogram bars\n",
    "colors = plt.get_cmap('Spectral')(np.linspace(0, 1, len(x_vals)))\n",
    "\n",
    "# Plot the histogram as bars with colors based on x-value\n",
    "plt.bar(x_vals, kde(x_vals), width=(x_vals[1]-x_vals[0]), color=colors, edgecolor='none')\n",
    "\n",
    "# Plot a line graph on top of the histogram\n",
    "plt.plot(x_vals, kde(x_vals), color='black')\n",
    "\n",
    "# Add a vertical line at x=0.49\n",
    "plt.axvline(x=0.49, color='black', linestyle='--') #change this value to the threshold value\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('RG Values')\n",
    "plt.ylabel('Density')\n",
    "plt.title('Smoothed Density Histogram')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function to count the number of infected pixels\n",
    "def count_pixels_below_threshold(rg):\n",
    "    # Flatten the exgr image into a 1D array\n",
    "    rg_flat = rg.ravel()\n",
    "\n",
    "    # Count the number of pixels below threshold\n",
    "    count = np.sum(rg_flat > 0.49) # change this value to the threshold value\n",
    "\n",
    "    return count\n",
    "\n",
    "# create a function to count the total number of pixels in the head\n",
    "def count_non_na_pixels(rg):\n",
    "    # Flatten the exgr image into a 1D array\n",
    "    rg_flat = rg.ravel()\n",
    "\n",
    "    # Count the number of non-NA pixels\n",
    "    count = np.sum(np.isfinite(rg_flat))\n",
    "\n",
    "    return count\n",
    "\n",
    "# count the total number of pixels below the threshold\n",
    "num_pixels_below_threshold = count_pixels_below_threshold(rg)\n",
    "\n",
    "# count the total number of pixels in the head\n",
    "num_non_na_pixels = count_non_na_pixels(rg)\n",
    "\n",
    "# calculate the proportion of pixels below the threshold\n",
    "sum = (num_pixels_below_threshold / num_non_na_pixels)*100\n",
    "print('The proportion of pixels below the threshold is', sum, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine the accuracy of the rg transformation severity estimations through stratified random sampling\n",
    "\n",
    "# Set the pixels within the mask to binary based on the rg value\n",
    "binary_mask = np.where((segmentation_mask > 0) & (rg > 0.49), 1, 0)\n",
    "\n",
    "# visualize the binary mask\n",
    "plt.imshow(binary_mask, cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "# Get the indices of all non-zero pixels in the binary mask\n",
    "indices = np.argwhere(segmentation_mask > 0)\n",
    "\n",
    "# Get the values of each pixel in the binary mask\n",
    "values = binary_mask[indices[:, 0], indices[:, 1]]\n",
    "\n",
    "# Perform stratified random sampling to select 30 indices with a proportional amount of 0s and 1s\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=30, random_state=42)\n",
    "train_index, test_index = next(sss.split(indices, values))\n",
    "\n",
    "# Get the selected indices and their corresponding values\n",
    "selected_indices = indices[test_index]\n",
    "selected_values = values[test_index]\n",
    "\n",
    "# Create a DataFrame to store the position and value of each selected pixel\n",
    "df = pd.DataFrame(columns=['Row', 'Column', 'Value'])\n",
    "\n",
    "# Loop through each selected index and record its position and value in a list of dictionaries\n",
    "data = []\n",
    "for index, value in zip(selected_indices, selected_values):\n",
    "    row, col = index\n",
    "    data.append({'Row': row, 'Column': col, 'Value': value})\n",
    "\n",
    "# Create a DataFrame from the list of dictionaries\n",
    "df = pd.DataFrame(data, columns=['Row', 'Column', 'Value'])\n",
    "\n",
    "# Print the DataFrame to the console\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize selected pixels on the image\n",
    "\n",
    "# Load the original RGB image\n",
    "img = cv2.imread(#path to image)\n",
    "\n",
    "# Set the row and column numbers for the desired pixel\n",
    "row_num = #enter row number\n",
    "col_num = #enter column number\n",
    "\n",
    "# Highlight the desired pixel in the image\n",
    "img_highlighted = img.copy()\n",
    "cv2.circle(img_highlighted, (col_num, row_num), 5, (0, 0, 255), -1)\n",
    "\n",
    "# Display the highlighted image using Matplotlib\n",
    "plt.imshow(cv2.cvtColor(img_highlighted, cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assess the accuracy of the rg transformation severity estimations \n",
    "\n",
    "# Load the Excel file into a DataFrame\n",
    "df = pd.read_excel(#path to Excel file with the estimated and observed severity scores)\n",
    "\n",
    "# Get the observed and predicted class labels from the DataFrame\n",
    "observed = df['Visual']\n",
    "predicted = df['Value']\n",
    "\n",
    "# Create a confusion matrix\n",
    "cm = confusion_matrix(observed, predicted)\n",
    "\n",
    "# Calculate accuracy, recall, precision, and F1 scores\n",
    "accuracy = accuracy_score(observed, predicted)\n",
    "recall = recall_score(observed, predicted, average='weighted')\n",
    "precision = precision_score(observed, predicted, average='weighted')\n",
    "f1 = f1_score(observed, predicted, average='weighted')\n",
    "\n",
    "# Display the confusion matrix as a heatmap using Matplotlib \n",
    "sns.heatmap(cm, annot=True, cmap='Blues', annot_kws={'size': 15})\n",
    "plt.xlabel('Predicted Class', fontsize=15)\n",
    "plt.ylabel('Observed Class', fontsize=15)\n",
    "plt.title('Confusion Matrix', fontsize=15)\n",
    "plt.show()\n",
    "\n",
    "# Print the scores to the console\n",
    "print('Accuracy:', accuracy)\n",
    "print('Recall:', recall)\n",
    "print('Precision:', precision)\n",
    "print('F1 Score:', f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaulate severity over a folder of images\n",
    "\n",
    "#set device to gpu\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def count_below_threshold(rg, threshold):\n",
    "    \"\"\"\n",
    "    Counts the number of pixels below the given threshold in the given exgr image.\n",
    "    \"\"\"\n",
    "    # Flatten the exgr image into a 1D array\n",
    "    rg_flat = rg.ravel()\n",
    "\n",
    "    # Count the number of pixels below the threshold\n",
    "    count = np.sum(rg_flat > threshold)\n",
    "\n",
    "    return count\n",
    "\n",
    "# set the path to the folder containing the images\n",
    "folder_path = # path to folder containing images\n",
    "\n",
    "# load the custom YOLO model\n",
    "weight = # path to custom YOLO object detection model\n",
    "model = YOLO(weight)\n",
    "\n",
    "# initialize a list to store the ratios for each image\n",
    "ratio = []\n",
    "isolate = []\n",
    "cultivar = []\n",
    "rep = []\n",
    "head = []\n",
    "DAI = []\n",
    "data = []\n",
    "\n",
    "# loop over all the files in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    # check if the file is an image\n",
    "    if filename.endswith('.png') or filename.endswith('.jpg'):\n",
    "         # extract isolate, cultivar, rep, and DAI information from the filename\n",
    "        isolate, cultivar, rep, head, DAI = filename.split('_')[:5]\n",
    "        # run the model on the image\n",
    "        image_path = os.path.join(folder_path, filename)\n",
    "        results = model.predict(image_path, conf=0.5)\n",
    "\n",
    "        # extract bounding box coordinates from the detection\n",
    "        for result in results:\n",
    "            boxes = result.boxes\n",
    "            if len(boxes) > 0:\n",
    "                bbox = boxes.xyxy.tolist()[0]\n",
    "                device = \"cuda\"\n",
    "\n",
    "        # run the segmentation model on the bounding box\n",
    "        image = cv2.cvtColor(cv2.imread(image_path), cv2.COLOR_BGR2RGB)\n",
    "        sam_checkpoint = \"sam_vit_h_4b8939.pth\"\n",
    "        model_type = \"vit_h\"\n",
    "        sam = sam_model_registry[model_type](checkpoint=sam_checkpoint)\n",
    "        sam.to(device=device)\n",
    "        predictor = SamPredictor(sam)\n",
    "        predictor.set_image(image)\n",
    "        input_box = np.array(bbox)\n",
    "        masks, _, _ = predictor.predict(\n",
    "            point_coords=None,\n",
    "            point_labels=None,\n",
    "            box=input_box[None, :],\n",
    "            multimask_output=False,\n",
    "        )\n",
    "        # Extract information from the file name\n",
    "        file_name = os.path.splitext(filename)[0]\n",
    "        name_parts = file_name.split(\"_\")\n",
    "        isolate_name = name_parts[0]\n",
    "        cultivar_name = name_parts[1]\n",
    "        rep = name_parts[2]\n",
    "        head_number = name_parts[3]\n",
    "        days_after_infection = name_parts[4]\n",
    "\n",
    "        #get the segmentation mask\n",
    "        segmentation_mask = masks[0]\n",
    "\n",
    "        # Convert the segmentation mask to a binary mask\n",
    "        binary_mask = np.where(segmentation_mask > 0.5, 1, 0)\n",
    "\n",
    "        #create a background with NA values\n",
    "        na_background = np.full_like(image, np.nan)\n",
    "\n",
    "        # Apply the binary mask\n",
    "        img_na = na_background * (1 - binary_mask[..., np.newaxis]) + image * binary_mask[..., np.newaxis]\n",
    "\n",
    "        s_r = img_na[:,:,0]\n",
    "        s_g = img_na[:,:,1]\n",
    "        s_b = img_na[:,:,2]\n",
    "\n",
    "        #performing the red/green ratio calculation\n",
    "        rg = s_r / (s_g + s_r)\n",
    "\n",
    "        # set the pixels on exgr that are not within the mask to NaN\n",
    "        rg[~segmentation_mask] = np.nan\n",
    "\n",
    "        # Calculate the total number of non-NA pixels\n",
    "        total_pixels = np.sum(np.isfinite(rg))\n",
    "\n",
    "        # Calculate the number of pixels below the threshold\n",
    "        threshold = 0.49 # change this value to the threshold value\n",
    "        below_threshold = count_below_threshold(rg, threshold)\n",
    "\n",
    "        # Calculate the ratio of pixels below the threshold to total pixels\n",
    "        ratio = below_threshold / total_pixels\n",
    "\n",
    "        image_info = {\n",
    "                        'Isolate': isolate_name,\n",
    "                        'Cultivar': cultivar_name,\n",
    "                        'Replication': rep,\n",
    "                        'Head': head_number,\n",
    "                        'DAI': days_after_infection,\n",
    "                        'Below Threshold': below_threshold,\n",
    "                        'Total Pixels': total_pixels,\n",
    "                        'Severity': ratio,\n",
    "                        \n",
    "                    }\n",
    "\n",
    "        data.append(image_info)\n",
    "        \n",
    "    # Create a DataFrame from the collected data\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "# Save the DataFrame to an Excel file\n",
    "df.to_csv(#path to savet csv file, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
